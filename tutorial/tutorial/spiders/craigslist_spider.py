import scrapy

class JobsSpider(scrapy.Spider):
    name = 'craigslist'
    start_urls = [
        'http://atlanta.craigslist.org/search/jjj?excats=12-1-2-1-7-1-1-1-1-1-19-1-1-3-2-1-2-2-2-14-25-25-1-1-1-1-1-1&is_telecommuting=1',
        'http://austin.craigslist.org/search/jjj?excats=12-1-2-1-7-1-1-1-1-1-19-1-1-3-2-1-2-2-2-14-25-25-1-1-1-1-1-1&is_telecommuting=1',
        'http://boston.craigslist.org/search/jjj?excats=12-1-2-1-7-1-1-1-1-1-19-1-1-3-2-1-2-2-2-14-25-25-1-1-1-1-1-1&is_telecommuting=1',
        'http://chicago.craigslist.org/search/jjj?excats=12-1-2-1-7-1-1-1-1-1-19-1-1-3-2-1-2-2-2-14-25-25-1-1-1-1-1-1&is_telecommuting=1',
        'http://dallas.craigslist.org/search/jjj?excats=12-1-2-1-7-1-1-1-1-1-19-1-1-3-2-1-2-2-2-14-25-25-1-1-1-1-1-1&is_telecommuting=1',
        'http://denver.craigslist.org/search/jjj?excats=12-1-2-1-7-1-1-1-1-1-19-1-1-3-2-1-2-2-2-14-25-25-1-1-1-1-1-1&is_telecommuting=1',
        'http://detroit.craigslist.org/search/jjj?excats=12-1-2-1-7-1-1-1-1-1-19-1-1-3-2-1-2-2-2-14-25-25-1-1-1-1-1-1&is_telecommuting=1',
        'http://houston.craigslist.org/search/jjj?excats=12-1-2-1-7-1-1-1-1-1-19-1-1-3-2-1-2-2-2-14-25-25-1-1-1-1-1-1&is_telecommuting=1',
        'http://lasvegas.craigslist.org/search/jjj?excats=12-1-2-1-7-1-1-1-1-1-19-1-1-3-2-1-2-2-2-14-25-25-1-1-1-1-1-1&is_telecommuting=1',
        'http://losangeles.craigslist.org/search/jjj?excats=12-1-2-1-7-1-1-1-1-1-19-1-1-3-2-1-2-2-2-14-25-25-1-1-1-1-1-1&is_telecommuting=1',
        'http://miami.craigslist.org/search/jjj?excats=12-1-2-1-7-1-1-1-1-1-19-1-1-3-2-1-2-2-2-14-25-25-1-1-1-1-1-1&is_telecommuting=1',
        'http://minneapolis.craigslist.org/search/jjj?excats=12-1-2-1-7-1-1-1-1-1-19-1-1-3-2-1-2-2-2-14-25-25-1-1-1-1-1-1&is_telecommuting=1',
        'http://newyork.craigslist.org/search/jjj?excats=12-1-2-1-7-1-1-1-1-1-19-1-1-3-2-1-2-2-2-14-25-25-1-1-1-1-1-1&is_telecommuting=1',
        'http://orangecounty.craigslist.org/search/jjj?excats=12-1-2-1-7-1-1-1-1-1-19-1-1-3-2-1-2-2-2-14-25-25-1-1-1-1-1-1&is_telecommuting=1',
        'http://philadelphia.craigslist.org/search/jjj?excats=12-1-2-1-7-1-1-1-1-1-19-1-1-3-2-1-2-2-2-14-25-25-1-1-1-1-1-1&is_telecommuting=1',
        'http://phoenix.craigslist.org/search/jjj?excats=12-1-2-1-7-1-1-1-1-1-19-1-1-3-2-1-2-2-2-14-25-25-1-1-1-1-1-1&is_telecommuting=1',
        'http://portland.craigslist.org/search/jjj?excats=12-1-2-1-7-1-1-1-1-1-19-1-1-3-2-1-2-2-2-14-25-25-1-1-1-1-1-1&is_telecommuting=1',
        'http://raleigh.craigslist.org/search/jjj?excats=12-1-2-1-7-1-1-1-1-1-19-1-1-3-2-1-2-2-2-14-25-25-1-1-1-1-1-1&is_telecommuting=1',
        'http://sacramento.craigslist.org/search/jjj?excats=12-1-2-1-7-1-1-1-1-1-19-1-1-3-2-1-2-2-2-14-25-25-1-1-1-1-1-1&is_telecommuting=1',
        'http://sandiego.craigslist.org/search/jjj?excats=12-1-2-1-7-1-1-1-1-1-19-1-1-3-2-1-2-2-2-14-25-25-1-1-1-1-1-1&is_telecommuting=1',
        'http://seattle.craigslist.org/search/jjj?excats=12-1-2-1-7-1-1-1-1-1-19-1-1-3-2-1-2-2-2-14-25-25-1-1-1-1-1-1&is_telecommuting=1',
        'http://sfbay.craigslist.org/search/jjj?excats=12-1-2-1-7-1-1-1-1-1-19-1-1-3-2-1-2-2-2-14-25-25-1-1-1-1-1-1&is_telecommuting=1',
        'http://washingtondc.craigslist.org/search/jjj?excats=12-1-2-1-7-1-1-1-1-1-19-1-1-3-2-1-2-2-2-14-25-25-1-1-1-1-1-1&is_telecommuting=1',
    ]

    def parse(self, response):
        # for result in response.css('li.result-row'):
        #     yield {
        #         'title': result.css('a.result-title::text').extract(),
        #         'url': result.css('a.result-title::attr(href)').extract(),
        #     }
        
        # follow links to listing pages
        for href in response.css('.result-info a::attr(href)').extract():
            yield scrapy.Request(response.urljoin(href),
                                callback=self.parse_listing)
    #     
    #     # follow pagination links
    #     next_page = response.css('span.next a::attr(href)').extract_first()
    #     if next_page is not None:
    #         next_page = response.urljoin(next_page)
    #         yield scrapy.Request(next_page, callback=self.parse)
    # 
    def parse_listing(self, response):
        yield {
            'title': response.css('#titletextonly::text').extract(),
            'date': response.css('#display-date time::text').extract(),
            'url': response.request.url
        }